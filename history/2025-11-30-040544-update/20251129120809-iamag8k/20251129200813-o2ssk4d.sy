{"ID":"20251129200813-o2ssk4d","Spec":"1","Type":"NodeDocument","Properties":{"id":"20251129200813-o2ssk4d","title":"基础环境搭建","type":"doc","updated":"20251130120448"},"Children":[{"ID":"20251129120813-k29tb5p","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20251129120813-k29tb5p","updated":"20251129201312"},"Children":[{"Type":"NodeText","Data":"yolov8m pt文件下载"}]},{"ID":"20251129200855-mhukk4t","Type":"NodeParagraph","Properties":{"id":"20251129200855-mhukk4t","updated":"20251129201027"},"Children":[{"Type":"NodeText","Data":"在此网站内下载权重文件，https://github.com/ultralytics/assets/releases"}]},{"ID":"20251129201312-ezjcfjb","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20251129201312-ezjcfjb","updated":"20251129201412"},"Children":[{"Type":"NodeText","Data":"ultralytics下载"}]},{"ID":"20251129201337-lxuylby","Type":"NodeParagraph","Properties":{"id":"20251129201337-lxuylby","updated":"20251129201412"},"Children":[{"Type":"NodeText","Data":"git clone https://github.com/ultralytics/ultralytics.git"}]},{"ID":"20251129200847-2lqspzh","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20251129200847-2lqspzh","updated":"20251129214416"},"Children":[{"Type":"NodeText","Data":"linux安装conda"}]},{"ID":"20251129201113-prb0dms","Type":"NodeParagraph","Properties":{"id":"20251129201113-prb0dms","updated":"20251129201113"},"Children":[{"Type":"NodeText","Data":"curl -O https://repo.anaconda.com/archive/Anaconda3-\u003cINSTALLER_VERSION\u003e-Linux-x86_64.sh"}]},{"ID":"20251129214416-3248wey","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20251129214416-3248wey","updated":"20251129214426"},"Children":[{"Type":"NodeText","Data":"yolo部署安装"}]},{"ID":"20251129201115-i3qcmre","Type":"NodeParagraph","Properties":{"id":"20251129201115-i3qcmre","updated":"20251129201233"},"Children":[{"Type":"NodeText","Data":"conda create -n yolov8 python=3.8"}]},{"ID":"20251129201216-duszd4t","Type":"NodeParagraph","Properties":{"id":"20251129201216-duszd4t","updated":"20251129201300"},"Children":[{"Type":"NodeText","Data":"conda activate yolov8"}]},{"ID":"20251129201431-x3z14f7","Type":"NodeParagraph","Properties":{"id":"20251129201431-x3z14f7","updated":"20251129201441"},"Children":[{"Type":"NodeText","Data":"cd ultralytics"}]},{"ID":"20251129201301-n1gya1g","Type":"NodeParagraph","Properties":{"id":"20251129201301-n1gya1g","updated":"20251129201430"},"Children":[{"Type":"NodeText","Data":"pip install -e . --index-url https://pypi.org/simple"}]},{"ID":"20251129202056-8kp71x0","Type":"NodeParagraph","Properties":{"id":"20251129202056-8kp71x0","updated":"20251129202254"},"Children":[{"Type":"NodeText","Data":"vim /root/ultralytics/ultralytics/cfg/default.yaml设置model位置，data设置为coco128.yaml"}]},{"ID":"20251129214334-8skp70a","Type":"NodeParagraph","Properties":{"id":"20251129214334-8skp70a","updated":"20251129214345"},"Children":[{"Type":"NodeText","Data":"yolo export model=yolov8m.pt format=onnx"}]},{"ID":"20251129214334-jazocp8","Type":"NodeParagraph","Properties":{"id":"20251129214334-jazocp8","updated":"20251129214401"},"Children":[{"Type":"NodeText","Data":"根据实际情况安装缺少的依赖，pip install --extra-index-url https://pypi.org/simple/ onnxslim==0.1.71"}]},{"ID":"20251129201036-p2l273n","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20251129201036-p2l273n","updated":"20251130120448"},"Children":[{"Type":"NodeText","Data":"将onnx转换为rknn"}]},{"ID":"20251129214501-3v8fr40","Type":"NodeParagraph","Properties":{"id":"20251129214501-3v8fr40","updated":"20251129214841"},"Children":[{"Type":"NodeText","Data":"git clone https://github.com/airockchip/rknn-toolkit2.git"}]},{"ID":"20251129214842-67ov20l","Type":"NodeParagraph","Properties":{"id":"20251129214842-67ov20l","updated":"20251129215848"},"Children":[{"Type":"NodeText","Data":"pip install -r requirements_cp38-2.3.2.txt -i https://mirrors.aliyun.com/pypi/simple"}]},{"ID":"20251129215850-wnq651h","Type":"NodeParagraph","Properties":{"id":"20251129215850-wnq651h","updated":"20251129223540"},"Children":[{"Type":"NodeText","Data":"pip install rknn_toolkit2-2.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"}]},{"ID":"20251129223550-4383qi5","Type":"NodeParagraph","Properties":{"id":"20251129223550-4383qi5","updated":"20251130114437"},"Children":[{"Type":"NodeText","Data":"git clone https://github.com/airockchip/rknn_model_zoo.git （此仓库包含转换代码、onnx文件及测试源码）"}]},{"ID":"20251130120354-t7lp85z","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"Properties":{"id":"20251130120354-t7lp85z","updated":"20251130120448"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```"},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"cHl0aG9u"},{"Type":"NodeCodeBlockCode","Data":"注：在datasets中放置自己需要训练的数据集进行训练\n"},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```"}]},{"ID":"20251130114611-9gn8rkp","Type":"NodeParagraph","Properties":{"id":"20251130114611-9gn8rkp","updated":"20251130115053"},"Children":[{"Type":"NodeText","Data":"进入examples下的yolov8中，在python目录下可以看到convert.py和test.py"}]},{"ID":"20251130115119-gf3hcpo","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"Properties":{"id":"20251130115119-gf3hcpo","updated":"20251130115132"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```"},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"c2hlbGw="},{"Type":"NodeCodeBlockCode","Data":"cd python\npython convert.py \u003connx_model\u003e \u003cTARGET_PLATFORM\u003e \u003cdtype(optional)\u003e \u003coutput_rknn_path(optional)\u003e\n\n# such as: \npython convert.py ../model/yolov8n.onnx rk3588\n# output model will be saved as ../model/yolov8.rknn\n"},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```"}]},{"ID":"20251130114241-xhhlepu","Type":"NodeParagraph","Properties":{"id":"20251130114241-xhhlepu","updated":"20251130115522"},"Children":[{"Type":"NodeText","Data":"生成的rknn文件就可以上传到开发板了。然后在开发板下载miniconda配置python虚拟环境："}]},{"ID":"20251130115522-lnjsnxb","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"Properties":{"id":"20251130115522-lnjsnxb","updated":"20251130115754"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```"},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"c2hlbGw="},{"Type":"NodeCodeBlockCode","Data":"wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh\nbash Miniconda3-latest-Linux-aarch64.sh \nource ~/.bashrc \n#与PC端环境保持一致\nconda create -n yolov8 python=3.8\nconda activate yolov8\n"},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```"}]},{"ID":"20251130115502-jflinnh","Type":"NodeParagraph","Properties":{"id":"20251130115502-jflinnh","updated":"20251130120006"},"Children":[{"Type":"NodeText","Data":"在开发板侧安装rknn_toolkit依赖："}]},{"ID":"20251130115831-79wglai","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"Properties":{"id":"20251130115831-79wglai","updated":"20251130120057"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```"},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"c2hlbGw="},{"Type":"NodeCodeBlockCode","Data":"git clone https://github.com/airockchip/rknn-toolkit2.git\n#使用lite2\ncd rknn-toolkit-lite2/packages/\npip install rknn_toolkit_lite2-2.3.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n"},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```"}]},{"ID":"20251129200838-lyck8q6","Type":"NodeParagraph","Properties":{"id":"20251129200838-lyck8q6","updated":"20251130120115"},"Children":[{"Type":"NodeText","Data":"结合test.py编写验证代码："}]},{"ID":"20251130120116-lbkh7lq","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"Properties":{"id":"20251130120116-lbkh7lq","updated":"20251130120255"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```"},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"cHl0aG9u"},{"Type":"NodeCodeBlockCode","Data":"import cv2\nimport numpy as np\nimport os\nimport time\n\nIMG_SIZE = (640, 640)  # (width, height), such as (1280, 736)\nOBJ_THRESH = 0.25\nNMS_THRESH = 0.45\nCLASSES = (\"person\", \"bicycle\", \"car\",\"motorbike \",\"aeroplane \",\"bus \",\"train\",\"truck \",\"boat\",\"traffic light\",\n           \"fire hydrant\",\"stop sign \",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog \",\"horse \",\"sheep\",\"cow\",\"elephant\",\n           \"bear\",\"zebra \",\"giraffe\",\"backpack\",\"umbrella\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\n           \"baseball bat\",\"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"wine glass\",\"cup\",\"fork\",\"knife \",\n           \"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza \",\"donut\",\"cake\",\"chair\",\"sofa\",\n           \"pottedplant\",\"bed\",\"diningtable\",\"toilet \",\"tvmonitor\",\"laptop\t\",\"mouse\t\",\"remote \",\"keyboard \",\"cell phone\",\"microwave \",\n           \"oven \",\"toaster\",\"sink\",\"refrigerator \",\"book\",\"clock\",\"vase\",\"scissors \",\"teddy bear \",\"hair drier\", \"toothbrush \")\n\n# !!! 核心修改 !!! 将 RKNN 替换为 RKNNLite\ntry:\n    from rknnlite.api import RKNNLite  # 使用轻量级 API\nexcept ImportError:\n    print(\"错误: 找不到 'rknnlite' 模块。请在 Python 3.8 环境中安装正确的 RKNN Runtime whl 包。\")\n    # 如果找不到 rknnlite，则使用 None 占位，避免程序崩溃\n    RKNNLite = None\n\n# =======================================================================\n# 1. 配置和模型路径\n# =======================================================================\nRKNN_MODEL_PATH = 'yolov8.rknn'\n#实际的控制节点\nDEVICE_SUBDEV = \"/dev/v4l-subdev3\"\nVIDEO_DEVICE = 11\n\n# YOLOv8m 的输入尺寸\nMODEL_INPUT_WIDTH = 640\nMODEL_INPUT_HEIGHT = 640\n\n# --- 硬件参数配置 (保持不变) ---\nprint(\"正在配置摄像头硬件参数...\")\nos.system(f\"v4l2-ctl -d {DEVICE_SUBDEV} --set-ctrl analogue_gain=2000\")\nos.system(f\"v4l2-ctl -d {DEVICE_SUBDEV} --set-ctrl exposure=3000\")\n\ncap = cv2.VideoCapture(VIDEO_DEVICE)\nif not cap.isOpened():\n    print(\"无法打开摄像头\")\n    exit()\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n\n# --- 2. RKNN 模型初始化 ---\nrknn = None\nif RKNNLite:\n    print(f\"--- 正在加载 RKNN 模型 (Lite): {RKNN_MODEL_PATH} ---\")\n    try:\n        # !!! 核心修改 !!! 使用 RKNNLite 实例化\n        rknn = RKNNLite(verbose=True)\n\n        ret = rknn.load_rknn(RKNN_MODEL_PATH)\n        if ret != 0:\n            print(\"错误: 加载 RKNN 模型失败！请检查路径。\")\n            rknn = None\n\n        # 初始化运行时环境 (在 NPU 上)\n        ret = rknn.init_runtime()\n        if ret != 0:\n            print(\"错误: 初始化 NPU 运行时失败！\")\n            rknn = None\n        else:\n            print(\"RKNN 模型加载并初始化成功。\")\n\n    except Exception as e:\n        print(f\"RKNN 初始化异常: {e}\")\n        rknn = None\n\n\n# --- 3. 自动白平衡函数 (保持不变) ---\ndef simple_white_balance(img):\n    b, g, r = cv2.split(img)\n    b_avg = np.mean(b);\n    g_avg = np.mean(g);\n    r_avg = np.mean(r)\n    k = (b_avg + g_avg + r_avg) / 3\n    b_avg = b_avg if b_avg != 0 else 1\n    g_avg = g_avg if g_avg != 0 else 1\n    r_avg = r_avg if r_avg != 0 else 1\n    kb = k / b_avg;\n    kg = k / g_avg;\n    kr = k / r_avg\n    b = np.clip(b * kb, 0, 255).astype(np.uint8)\n    g = np.clip(g * kg, 0, 255).astype(np.uint8)\n    r = np.clip(r * kr, 0, 255).astype(np.uint8)\n    return cv2.merge([b, g, r])\n\ndef filter_boxes(boxes, box_confidences, box_class_probs):\n    \"\"\"Filter boxes with object threshold.\n    \"\"\"\n    box_confidences = box_confidences.reshape(-1)\n    candidate, class_num = box_class_probs.shape\n\n    class_max_score = np.max(box_class_probs, axis=-1)\n    classes = np.argmax(box_class_probs, axis=-1)\n\n    _class_pos = np.where(class_max_score* box_confidences \u003e= OBJ_THRESH)\n    scores = (class_max_score* box_confidences)[_class_pos]\n\n    boxes = boxes[_class_pos]\n    classes = classes[_class_pos]\n\n    return boxes, classes, scores\n\n# --- 4. YOLOv8 预处理函数 (保持不变) ---\ndef preprocess(img):\n    \"\"\"缩放图像并归一化到模型输入格式 (RGB, 640x640)\"\"\"\n    resized_img = cv2.resize(img, (MODEL_INPUT_WIDTH, MODEL_INPUT_HEIGHT), interpolation=cv2.INTER_LINEAR)\n    img_rgb = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n    input_data = img_rgb.astype(np.float32)\n    input_data = np.expand_dims(input_data, axis=0)  # (1, 640, 640, 3) NHWC format\n    return input_data\n\ndef nms_boxes(boxes, scores):\n    \"\"\"Suppress non-maximal boxes.\n    # Returns\n        keep: ndarray, index of effective boxes.\n    \"\"\"\n    x = boxes[:, 0]\n    y = boxes[:, 1]\n    w = boxes[:, 2] - boxes[:, 0]\n    h = boxes[:, 3] - boxes[:, 1]\n\n    areas = w * h\n    order = scores.argsort()[::-1]\n\n    keep = []\n    while order.size \u003e 0:\n        i = order[0]\n        keep.append(i)\n\n        xx1 = np.maximum(x[i], x[order[1:]])\n        yy1 = np.maximum(y[i], y[order[1:]])\n        xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])\n        yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])\n\n        w1 = np.maximum(0.0, xx2 - xx1 + 0.00001)\n        h1 = np.maximum(0.0, yy2 - yy1 + 0.00001)\n        inter = w1 * h1\n\n        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n        inds = np.where(ovr \u003c= NMS_THRESH)[0]\n        order = order[inds + 1]\n    keep = np.array(keep)\n    return keep\n\n\ndef dfl(position):\n    \"\"\"用纯 NumPy 实现 YOLOv8 的 DFL 解码。\"\"\"\n    x = np.asarray(position, dtype=np.float32)\n    n, c, h, w = x.shape\n    p_num = 4\n    mc = c // p_num\n    y = x.reshape(n, p_num, mc, h, w)\n\n    # NumPy Softmax (沿第 2 轴)\n    e_x = np.exp(y - np.max(y, axis=2, keepdims=True))\n    y = e_x / np.sum(e_x, axis=2, keepdims=True)\n\n    # 累积矩阵和加权求和\n    acc_matrix = np.arange(mc, dtype=np.float32).reshape(1, 1, mc, 1, 1)\n    y = (y * acc_matrix).sum(axis=2)\n\n    return y\n\ndef box_process(position):\n    grid_h, grid_w = position.shape[2:4]\n    col, row = np.meshgrid(np.arange(0, grid_w), np.arange(0, grid_h))\n    col = col.reshape(1, 1, grid_h, grid_w)\n    row = row.reshape(1, 1, grid_h, grid_w)\n    grid = np.concatenate((col, row), axis=1)\n    stride = np.array([IMG_SIZE[1]//grid_h, IMG_SIZE[0]//grid_w]).reshape(1,2,1,1)\n\n    position = dfl(position)\n    box_xy  = grid +0.5 -position[:,0:2,:,:]\n    box_xy2 = grid +0.5 +position[:,2:4,:,:]\n    xyxy = np.concatenate((box_xy*stride, box_xy2*stride), axis=1)\n\n    return xyxy\n\ndef post_process(input_data):\n    boxes, scores, classes_conf = [], [], []\n    defualt_branch=3\n    pair_per_branch = len(input_data)//defualt_branch\n    # Python 忽略 score_sum 输出\n    for i in range(defualt_branch):\n        boxes.append(box_process(input_data[pair_per_branch*i]))\n        classes_conf.append(input_data[pair_per_branch*i+1])\n        scores.append(np.ones_like(input_data[pair_per_branch*i+1][:,:1,:,:], dtype=np.float32))\n\n    def sp_flatten(_in):\n        ch = _in.shape[1]\n        _in = _in.transpose(0,2,3,1)\n        return _in.reshape(-1, ch)\n\n    boxes = [sp_flatten(_v) for _v in boxes]\n    classes_conf = [sp_flatten(_v) for _v in classes_conf]\n    scores = [sp_flatten(_v) for _v in scores]\n\n    boxes = np.concatenate(boxes)\n    classes_conf = np.concatenate(classes_conf)\n    scores = np.concatenate(scores)\n\n    # filter according to threshold\n    boxes, classes, scores = filter_boxes(boxes, scores, classes_conf)\n\n    # nms\n    nboxes, nclasses, nscores = [], [], []\n    for c in set(classes):\n        inds = np.where(classes == c)\n        b = boxes[inds]\n        c = classes[inds]\n        s = scores[inds]\n        keep = nms_boxes(b, s)\n\n        if len(keep) != 0:\n            nboxes.append(b[keep])\n            nclasses.append(c[keep])\n            nscores.append(s[keep])\n\n    if not nclasses and not nscores:\n        return None, None, None\n\n    boxes = np.concatenate(nboxes)\n    classes = np.concatenate(nclasses)\n    scores = np.concatenate(nscores)\n\n    return boxes, classes, scores\n\n\n# --- 5. YOLOv8 后处理和画框函数 (保持占位符，需自行实现) ---\n# **重要提示：您需要根据您的 RKNN 模型输出结构实现这个函数**\ndef postprocess_and_draw(rknn_outputs, original_frame):\n    \"\"\"\n    使用 RKNN 示例脚本的逻辑对 NPU 输出进行后处理和绘图。\n    \"\"\"\n\n    if rknn_outputs and rknn_outputs[0].ndim \u003e= 2:\n        print(f\"RKNN Output Shape: {rknn_outputs[0].shape}\")\n    # 假设输出张量是 rknn_outputs[0]\n    else:\n        print(\"RKNN Output is invalid or has low dimensions.\")\n\n    # 1. 调用 RKNN 示例脚本的 post_process 函数\n    # 注意: YOLOv8 模型的 RKNN 输出可能需要特殊处理，这里直接传入 NPU 原始输出\n    boxes, classes, scores = post_process(rknn_outputs)\n\n    # 如果没有检测到目标，直接返回原图\n    if boxes is None:\n        return original_frame\n\n    # 初始化 COCO_test_helper（用于坐标映射）\n    # 在这个实时脚本中，我们简化这个工具类，直接进行简单的缩放和映射。\n\n    H, W, _ = original_frame.shape  # 原始视频帧尺寸 (640x480)\n\n    # 2. 坐标映射（从 640x640 映射回 640x480）\n\n    # 假设您的预处理没有进行 letterbox (即非等比缩放或直接 resize)，\n    # 且输入图像为 640x640，目标帧为 640x480。\n\n    # 我们必须将 640x640 上的坐标 (boxes) 缩放到原始 640x480 画面。\n\n    # 缩放因子：\n    scale_w = W / IMG_SIZE[0]  # 640/640 = 1.0\n    scale_h = H / IMG_SIZE[1]  # 480/640 = 0.75 (如果原始帧是 480 高度)\n\n    # YOLOv8 的 boxes 格式通常是 [x1, y1, x2, y2]\n    final_boxes = boxes.copy()\n    final_boxes[:, [0, 2]] *= scale_w  # 映射 X 坐标\n    final_boxes[:, [1, 3]] *= scale_h  # 映射 Y 坐标\n\n    # 3. 绘图\n    for box, score, cl in zip(final_boxes, scores, classes):\n        # top, left, right, bottom 对应于 x_min, y_min, x_max, y_max\n        x1, y1, x2, y2 = [int(_b) for _b in box]\n\n        # 针对人脸模型，类别名称可能只需要 \"Face\"\n        class_name = CLASSES[cl] if cl \u003c len(CLASSES) else \"Unknown\"\n\n        # 绘制红色矩形框 (BGR: (0, 0, 255))\n        cv2.rectangle(original_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n        cv2.putText(original_frame, f'{class_name}: {score:.2f}', (x1, y1 - 10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n\n    return original_frame\n\n\n# --- 6. 主循环 ---\nenable_wb = True\nenable_flip = True\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    display_frame = frame.copy()\n\n    # 1. 软件白平衡处理\n    if enable_wb:\n        display_frame = simple_white_balance(display_frame)\n\n    # 2. 上下反转画面 (垂直反转)\n    if enable_flip:\n        display_frame = cv2.flip(display_frame, 0)\n\n    # 3. NPU 推理和人脸识别\n    if rknn:\n        # 预处理：缩放并转换颜色通道\n        # 注意：rknnlite.inference 期望输入是 NHWC 格式 (1, 640, 640, 3)\n        input_data = preprocess(display_frame)\n\n        # 推理\n        # data_format=['nhwc'] 告诉 rknn 你的输入数据是 NHWC 格式\n        outputs = rknn.inference(inputs=[input_data], data_format=['nhwc'])\n\n        # 后处理和绘图\n        display_frame = postprocess_and_draw(outputs, display_frame)\n\n    cv2.imshow('frame', display_frame)\n\n    key = cv2.waitKey(1) \u0026 0xFF\n    if key == ord('q'):\n        break\n\ncap.release()\nif rknn:\n    rknn.release()  # 释放 NPU 资源\ncv2.destroyAllWindows()\n"},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```"}]},{"ID":"20251130120128-d4bhnrb","Type":"NodeParagraph","Properties":{"id":"20251130120128-d4bhnrb","updated":"20251130120154"}}]}